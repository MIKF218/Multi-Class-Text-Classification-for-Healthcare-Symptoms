{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e9ef39",
   "metadata": {},
   "source": [
    "# Healthcare Symptoms ‚Üí Disease Classification\n",
    "\n",
    "This notebook implements the second project specification:\n",
    "\n",
    "> **Multi-Class Text Classification for Healthcare Symptoms ‚Üí Disease**\n",
    ">\n",
    "> Dataset: *Healthcare Symptoms‚ÄìDisease Classification* (Kaggle)\n",
    ">\n",
    "> Goal: Given a short text describing symptoms, build models that predict the corresponding disease class.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Load and inspect the dataset.\n",
    "2. Analyse three **labeling scenarios**:\n",
    "   - **Scenario A ‚Äì Raw Diseases (no noise removal)**  \n",
    "   - **Scenario B ‚Äì Cleaned Diseases (canonical disease per symptom text)**  \n",
    "   - **Scenario C ‚Äì Symptom-Based Clusters (K-Means groups)**  \n",
    "3. For the **final modelling step**, compare four models on one chosen scenario:\n",
    "   - Classic ML model with text embeddings (**TF‚ÄëIDF + Logistic Regression**)\n",
    "   - Simple feed-forward neural network on embeddings (**SimpleNN**)\n",
    "   - **RNN** model\n",
    "   - **LSTM** model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929741e",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd02f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff3e2f",
   "metadata": {},
   "source": [
    "## 1. Load Dataset & Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf06d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset shape: (25000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Symptom_Count</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>fever, back pain, shortness of breath</td>\n",
       "      <td>3</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>insomnia, back pain, weight loss</td>\n",
       "      <td>3</td>\n",
       "      <td>Thyroid Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>sore throat, vomiting, diarrhea</td>\n",
       "      <td>3</td>\n",
       "      <td>Influenza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>Other</td>\n",
       "      <td>blurred vision, depression, weight loss, muscle pain</td>\n",
       "      <td>4</td>\n",
       "      <td>Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>Female</td>\n",
       "      <td>swelling, appetite loss, nausea</td>\n",
       "      <td>3</td>\n",
       "      <td>Heart Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Age  Gender  \\\n",
       "0           1   29    Male   \n",
       "1           2   76  Female   \n",
       "2           3   78    Male   \n",
       "3           4   58   Other   \n",
       "4           5   55  Female   \n",
       "\n",
       "                                               Symptoms  Symptom_Count  \\\n",
       "0                 fever, back pain, shortness of breath              3   \n",
       "1                      insomnia, back pain, weight loss              3   \n",
       "2                       sore throat, vomiting, diarrhea              3   \n",
       "3  blurred vision, depression, weight loss, muscle pain              4   \n",
       "4                       swelling, appetite loss, nausea              3   \n",
       "\n",
       "            Disease  \n",
       "0           Allergy  \n",
       "1  Thyroid Disorder  \n",
       "2         Influenza  \n",
       "3            Stroke  \n",
       "4     Heart Disease  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning duplicates: (25000, 6)\n",
      "Number of unique diseases: 30\n",
      "Disease\n",
      "Anxiety           911\n",
      "Arthritis         896\n",
      "Food Poisoning    871\n",
      "Depression        859\n",
      "Allergy           858\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Path assumes Healthcare.csv is in the same folder as this notebook\n",
    "DATA_PATH = \"./Healthcare.csv\"\n",
    "\n",
    "# 1.1 Load raw dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Raw dataset shape: {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "# 1.2 Basic cleaning\n",
    "# - Drop duplicate rows\n",
    "# - Lowercase symptoms and strip whitespace\n",
    "df = df.drop_duplicates().copy()\n",
    "df[\"Symptoms\"] = df[\"Symptoms\"].str.lower().str.strip()\n",
    "\n",
    "print(f\"\\nAfter cleaning duplicates: {df.shape}\")\n",
    "print(\"Number of unique diseases:\", df[\"Disease\"].nunique())\n",
    "print(df[\"Disease\"].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f9d11",
   "metadata": {},
   "source": [
    "## 2. Utility ‚Äì Baseline Trainer (TF‚ÄëIDF + Logistic Regression)\n",
    "\n",
    "This helper encapsulates the repeated steps for the classic model:\n",
    "\n",
    "- Train/test split (80/20, stratified)\n",
    "- TF‚ÄëIDF vectorisation\n",
    "- Logistic Regression training\n",
    "- Accuracy + most-frequent-class baseline + classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ed832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg_tfidf(texts, labels, description=\"Scenario\"):\n",
    "    \"\"\"Train & evaluate TF‚ÄëIDF + Logistic Regression baseline.\n",
    "\n",
    "    Returns (accuracy, classifier, tfidf_vectorizer,\n",
    "             X_train_text, X_test_text, y_train, y_test).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{description}: TF‚ÄëIDF + Logistic Regression\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        texts,\n",
    "        labels,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=labels,\n",
    "    )\n",
    "\n",
    "    # TF‚ÄëIDF vectorisation\n",
    "    tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_vec = tfidf.fit_transform(X_train_text)\n",
    "    X_test_vec = tfidf.transform(X_test_text)\n",
    "\n",
    "    print(\"TF‚ÄëIDF shapes:\", X_train_vec.shape, X_test_vec.shape)\n",
    "\n",
    "    # Logistic Regression classifier\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        multi_class=\"multinomial\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Most-frequent-class baseline for comparison\n",
    "    majority = pd.Series(y_train).value_counts(normalize=True).iloc[0]\n",
    "\n",
    "    print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "    print(f\"Most-frequent-class baseline: {majority:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    return acc, clf, tfidf, X_train_text, X_test_text, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e8001",
   "metadata": {},
   "source": [
    "## 3. Scenario A ‚Äì Raw Diseases (No Noise Removal)\n",
    "\n",
    "In Scenario A we directly predict the original **Disease** label from the symptom text, without any attempt to clean noisy labels.\n",
    "\n",
    "This reflects the \"naive\" formulation of the problem and serves as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e1907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disease classes (raw): 30\n",
      "\n",
      "================================================================================\n",
      "Scenario A ‚Äì Raw Diseases: TF‚ÄëIDF + Logistic Regression\n",
      "================================================================================\n",
      "TF‚ÄëIDF shapes: (20000, 649) (5000, 649)\n",
      "\n",
      "Accuracy: 0.0336\n",
      "Most-frequent-class baseline: 0.0365\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.036     0.041     0.038       172\n",
      "           1      0.056     0.055     0.056       163\n",
      "           2      0.018     0.027     0.022       182\n",
      "           3      0.034     0.056     0.042       179\n",
      "           4      0.029     0.019     0.023       156\n",
      "           5      0.055     0.053     0.054       171\n",
      "           6      0.025     0.024     0.024       168\n",
      "           7      0.027     0.025     0.026       161\n",
      "           8      0.031     0.031     0.031       161\n",
      "           9      0.034     0.030     0.032       165\n",
      "          10      0.034     0.035     0.034       172\n",
      "          11      0.015     0.012     0.013       171\n",
      "          12      0.006     0.006     0.006       170\n",
      "          13      0.033     0.036     0.035       166\n",
      "          14      0.027     0.034     0.030       174\n",
      "          15      0.015     0.012     0.014       161\n",
      "          16      0.063     0.050     0.056       161\n",
      "          17      0.029     0.030     0.030       166\n",
      "          18      0.045     0.048     0.047       166\n",
      "          19      0.018     0.012     0.015       165\n",
      "          20      0.022     0.024     0.023       166\n",
      "          21      0.073     0.082     0.077       171\n",
      "          22      0.006     0.006     0.006       164\n",
      "          23      0.055     0.055     0.055       165\n",
      "          24      0.026     0.030     0.028       166\n",
      "          25      0.011     0.006     0.008       159\n",
      "          26      0.043     0.038     0.040       158\n",
      "          27      0.012     0.012     0.012       171\n",
      "          28      0.083     0.061     0.071       163\n",
      "          29      0.055     0.054     0.054       167\n",
      "\n",
      "    accuracy                          0.034      5000\n",
      "   macro avg      0.034     0.033     0.033      5000\n",
      "weighted avg      0.034     0.034     0.033      5000\n",
      "\n",
      "\n",
      "Scenario A final accuracy: 0.0336\n"
     ]
    }
   ],
   "source": [
    "# Encode raw Disease labels to integers\n",
    "le_raw = LabelEncoder()\n",
    "df[\"Disease_id_raw\"] = le_raw.fit_transform(df[\"Disease\"])\n",
    "\n",
    "print(\"Number of disease classes (raw):\", len(le_raw.classes_))\n",
    "\n",
    "acc_raw, clf_raw, tfidf_raw, X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_logreg_tfidf(\n",
    "    texts=df[\"Symptoms\"],\n",
    "    labels=df[\"Disease_id_raw\"],\n",
    "    description=\"Scenario A ‚Äì Raw Diseases\",\n",
    ")\n",
    "\n",
    "print(f\"\\nScenario A final accuracy: {acc_raw:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959edcf8",
   "metadata": {},
   "source": [
    "## 4. Scenario B ‚Äì Cleaned Diseases (Canonical Label per Symptom)\n",
    "\n",
    "In Scenario B we clean noisy labels at the **symptom-text** level:\n",
    "\n",
    "- For each unique `Symptoms` string, count how often each disease appears.\n",
    "- If one disease accounts for at least 80% of occurrences, we treat it as the **canonical** disease for that symptom pattern.\n",
    "- Symptom patterns without a dominant disease are considered ambiguous and are removed.\n",
    "\n",
    "This enforces a consistent mapping: *each symptom text ‚Üí one disease*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89667db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of symptom ‚Üí disease frequency table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>disease_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdominal pain, anxiety, appetite loss, nausea, blurred vision</td>\n",
       "      <td>{'Food Poisoning': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdominal pain, anxiety, back pain, rash, headache</td>\n",
       "      <td>{'Depression': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdominal pain, anxiety, back pain, weight loss</td>\n",
       "      <td>{'Liver Disease': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdominal pain, anxiety, blurred vision, chest pain</td>\n",
       "      <td>{'Hypertension': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdominal pain, anxiety, blurred vision, dizziness, weight gain, tremors, sore throat</td>\n",
       "      <td>{'Allergy': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Symptoms  \\\n",
       "0                         abdominal pain, anxiety, appetite loss, nausea, blurred vision   \n",
       "1                                     abdominal pain, anxiety, back pain, rash, headache   \n",
       "2                                        abdominal pain, anxiety, back pain, weight loss   \n",
       "3                                    abdominal pain, anxiety, blurred vision, chest pain   \n",
       "4  abdominal pain, anxiety, blurred vision, dizziness, weight gain, tremors, sore throat   \n",
       "\n",
       "          disease_counts  \n",
       "0  {'Food Poisoning': 1}  \n",
       "1      {'Depression': 1}  \n",
       "2   {'Liver Disease': 1}  \n",
       "3    {'Hypertension': 1}  \n",
       "4         {'Allergy': 1}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After canonical mapping (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>disease_counts</th>\n",
       "      <th>canonical_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdominal pain, anxiety, appetite loss, nausea, blurred vision</td>\n",
       "      <td>{'Food Poisoning': 1}</td>\n",
       "      <td>Food Poisoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdominal pain, anxiety, back pain, rash, headache</td>\n",
       "      <td>{'Depression': 1}</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdominal pain, anxiety, back pain, weight loss</td>\n",
       "      <td>{'Liver Disease': 1}</td>\n",
       "      <td>Liver Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdominal pain, anxiety, blurred vision, chest pain</td>\n",
       "      <td>{'Hypertension': 1}</td>\n",
       "      <td>Hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdominal pain, anxiety, blurred vision, dizziness, weight gain, tremors, sore throat</td>\n",
       "      <td>{'Allergy': 1}</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abdominal pain, anxiety, blurred vision, tremors, sweating, appetite loss</td>\n",
       "      <td>{'Epilepsy': 1}</td>\n",
       "      <td>Epilepsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abdominal pain, anxiety, chest pain, weight gain</td>\n",
       "      <td>{'Diabetes': 1}</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abdominal pain, anxiety, depression, sneezing, tremors</td>\n",
       "      <td>{'COVID-19': 1}</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abdominal pain, anxiety, depression, weight gain, back pain, nausea, dizziness</td>\n",
       "      <td>{'Gastritis': 1}</td>\n",
       "      <td>Gastritis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abdominal pain, anxiety, diarrhea</td>\n",
       "      <td>{'Liver Disease': 1}</td>\n",
       "      <td>Liver Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Symptoms  \\\n",
       "0                         abdominal pain, anxiety, appetite loss, nausea, blurred vision   \n",
       "1                                     abdominal pain, anxiety, back pain, rash, headache   \n",
       "2                                        abdominal pain, anxiety, back pain, weight loss   \n",
       "3                                    abdominal pain, anxiety, blurred vision, chest pain   \n",
       "4  abdominal pain, anxiety, blurred vision, dizziness, weight gain, tremors, sore throat   \n",
       "5              abdominal pain, anxiety, blurred vision, tremors, sweating, appetite loss   \n",
       "6                                       abdominal pain, anxiety, chest pain, weight gain   \n",
       "7                                 abdominal pain, anxiety, depression, sneezing, tremors   \n",
       "8         abdominal pain, anxiety, depression, weight gain, back pain, nausea, dizziness   \n",
       "9                                                      abdominal pain, anxiety, diarrhea   \n",
       "\n",
       "          disease_counts canonical_disease  \n",
       "0  {'Food Poisoning': 1}    Food Poisoning  \n",
       "1      {'Depression': 1}        Depression  \n",
       "2   {'Liver Disease': 1}     Liver Disease  \n",
       "3    {'Hypertension': 1}      Hypertension  \n",
       "4         {'Allergy': 1}           Allergy  \n",
       "5        {'Epilepsy': 1}          Epilepsy  \n",
       "6        {'Diabetes': 1}          Diabetes  \n",
       "7        {'COVID-19': 1}          COVID-19  \n",
       "8       {'Gastritis': 1}         Gastritis  \n",
       "9   {'Liver Disease': 1}     Liver Disease  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non‚Äëambiguous symptom patterns: 23789\n",
      "\n",
      "Cleaned dataset: kept 23806 of 25000 rows (95.2%).\n",
      "Number of distinct canonical diseases: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Canonical_Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fever, back pain, shortness of breath</td>\n",
       "      <td>Allergy</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insomnia, back pain, weight loss</td>\n",
       "      <td>Thyroid Disorder</td>\n",
       "      <td>Thyroid Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sore throat, vomiting, diarrhea</td>\n",
       "      <td>Influenza</td>\n",
       "      <td>Influenza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blurred vision, depression, weight loss, muscle pain</td>\n",
       "      <td>Stroke</td>\n",
       "      <td>Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swelling, appetite loss, nausea</td>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Heart Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vomiting, swelling, dizziness, fatigue</td>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Heart Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anxiety, shortness of breath, appetite loss, cough, back pain</td>\n",
       "      <td>Food Poisoning</td>\n",
       "      <td>Food Poisoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sore throat, weight loss, chest pain, depression, anxiety, rash</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>Bronchitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>insomnia, diarrhea, swelling</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>joint pain, shortness of breath, runny nose</td>\n",
       "      <td>Dermatitis</td>\n",
       "      <td>Dermatitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Symptoms  \\\n",
       "0                            fever, back pain, shortness of breath   \n",
       "1                                 insomnia, back pain, weight loss   \n",
       "2                                  sore throat, vomiting, diarrhea   \n",
       "3             blurred vision, depression, weight loss, muscle pain   \n",
       "4                                  swelling, appetite loss, nausea   \n",
       "5                           vomiting, swelling, dizziness, fatigue   \n",
       "6    anxiety, shortness of breath, appetite loss, cough, back pain   \n",
       "7  sore throat, weight loss, chest pain, depression, anxiety, rash   \n",
       "8                                     insomnia, diarrhea, swelling   \n",
       "9                      joint pain, shortness of breath, runny nose   \n",
       "\n",
       "            Disease Canonical_Disease  \n",
       "0           Allergy           Allergy  \n",
       "1  Thyroid Disorder  Thyroid Disorder  \n",
       "2         Influenza         Influenza  \n",
       "3            Stroke            Stroke  \n",
       "4     Heart Disease     Heart Disease  \n",
       "5     Heart Disease     Heart Disease  \n",
       "6    Food Poisoning    Food Poisoning  \n",
       "7        Bronchitis        Bronchitis  \n",
       "8          COVID-19          COVID-19  \n",
       "9        Dermatitis        Dermatitis  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 4.1 Build counts of diseases for each Symptoms string\n",
    "symptom_disease_counts = (\n",
    "    df.groupby(\"Symptoms\")\n",
    "      .agg({\"Disease\": lambda x: Counter(x)})\n",
    "      .reset_index()\n",
    "      .rename(columns={\"Disease\": \"disease_counts\"})\n",
    ")\n",
    "\n",
    "print(\"\\nSample of symptom ‚Üí disease frequency table:\")\n",
    "display(symptom_disease_counts.head())\n",
    "\n",
    "# 4.2 Decide canonical disease for a symptom pattern\n",
    "def choose_canonical_disease(counter: Counter, min_ratio: float = 0.8):\n",
    "    \"\"\"Return dominant disease if its share ‚â• min_ratio; otherwise None.\"\"\"\n",
    "    total = sum(counter.values())\n",
    "    disease, count = counter.most_common(1)[0]\n",
    "    if count / total >= min_ratio:\n",
    "        return disease\n",
    "    return None\n",
    "\n",
    "symptom_disease_counts[\"canonical_disease\"] = symptom_disease_counts[\"disease_counts\"].apply(\n",
    "    lambda c: choose_canonical_disease(c, min_ratio=0.8)\n",
    ")\n",
    "\n",
    "print(\"\\nAfter canonical mapping (first 10 rows):\")\n",
    "display(symptom_disease_counts.head(10))\n",
    "\n",
    "# 4.3 Map back to the full dataframe and drop ambiguous rows\n",
    "symptom2disease = (\n",
    "    symptom_disease_counts.dropna(subset=[\"canonical_disease\"])\n",
    "    .set_index(\"Symptoms\")[\"canonical_disease\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "print(\"\\nNon‚Äëambiguous symptom patterns:\", len(symptom2disease))\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean[\"Canonical_Disease\"] = df_clean[\"Symptoms\"].map(symptom2disease)\n",
    "\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=[\"Canonical_Disease\"])\n",
    "after = len(df_clean)\n",
    "\n",
    "print(f\"\\nCleaned dataset: kept {after} of {before} rows ({after/before:.1%}).\")\n",
    "print(\"Number of distinct canonical diseases:\", df_clean[\"Canonical_Disease\"].nunique())\n",
    "display(df_clean[[\"Symptoms\", \"Disease\", \"Canonical_Disease\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c21593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disease classes (cleaned): 30\n",
      "\n",
      "================================================================================\n",
      "Scenario B ‚Äì Cleaned Diseases: TF‚ÄëIDF + Logistic Regression\n",
      "================================================================================\n",
      "TF‚ÄëIDF shapes: (19044, 649) (4762, 649)\n",
      "\n",
      "Accuracy: 0.0338\n",
      "Most-frequent-class baseline: 0.0367\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.034     0.037     0.036       161\n",
      "           1      0.028     0.026     0.027       156\n",
      "           2      0.049     0.074     0.059       175\n",
      "           3      0.066     0.095     0.078       169\n",
      "           4      0.038     0.027     0.031       150\n",
      "           5      0.028     0.030     0.029       164\n",
      "           6      0.048     0.037     0.042       160\n",
      "           7      0.007     0.006     0.007       154\n",
      "           8      0.019     0.019     0.019       154\n",
      "           9      0.050     0.052     0.051       155\n",
      "          10      0.046     0.042     0.044       165\n",
      "          11      0.015     0.012     0.014       161\n",
      "          12      0.028     0.031     0.029       162\n",
      "          13      0.021     0.025     0.023       158\n",
      "          14      0.046     0.060     0.052       167\n",
      "          15      0.022     0.019     0.021       155\n",
      "          16      0.043     0.033     0.037       152\n",
      "          17      0.022     0.019     0.020       157\n",
      "          18      0.032     0.019     0.024       157\n",
      "          19      0.046     0.038     0.041       159\n",
      "          20      0.037     0.038     0.038       156\n",
      "          21      0.039     0.037     0.038       163\n",
      "          22      0.026     0.032     0.029       155\n",
      "          23      0.025     0.025     0.025       159\n",
      "          24      0.050     0.057     0.053       159\n",
      "          25      0.035     0.026     0.030       151\n",
      "          26      0.022     0.026     0.024       152\n",
      "          27      0.027     0.024     0.026       164\n",
      "          28      0.023     0.019     0.021       155\n",
      "          29      0.013     0.013     0.013       157\n",
      "\n",
      "    accuracy                          0.034      4762\n",
      "   macro avg      0.033     0.033     0.033      4762\n",
      "weighted avg      0.033     0.034     0.033      4762\n",
      "\n",
      "\n",
      "Scenario B final accuracy: 0.0338\n"
     ]
    }
   ],
   "source": [
    "# 4.4 Encode canonical diseases\n",
    "le_clean = LabelEncoder()\n",
    "df_clean[\"Disease_id_clean\"] = le_clean.fit_transform(df_clean[\"Canonical_Disease\"])\n",
    "\n",
    "print(\"Number of disease classes (cleaned):\", len(le_clean.classes_))\n",
    "\n",
    "# 4.5 Train baseline on cleaned labels\n",
    "acc_clean, clf_clean, tfidf_clean, X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_logreg_tfidf(\n",
    "    texts=df_clean[\"Symptoms\"],\n",
    "    labels=df_clean[\"Disease_id_clean\"],\n",
    "    description=\"Scenario B ‚Äì Cleaned Diseases\",\n",
    ")\n",
    "\n",
    "print(f\"\\nScenario B final accuracy: {acc_clean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9870c5",
   "metadata": {},
   "source": [
    "## 5. Scenario C ‚Äì Symptom-Based Clusters (K‚ÄëMeans Groups)\n",
    "\n",
    "In Scenario C we relax the problem: instead of predicting the exact disease, we let the data define broader **symptom groups** using K‚ÄëMeans clustering.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Vectorise all symptom strings using `CountVectorizer`.\n",
    "2. Run `KMeans(n_clusters = 5)` on these vectors.\n",
    "3. Use the resulting `Cluster_Label` as the target class.\n",
    "4. Train TF‚ÄëIDF + Logistic Regression to predict the cluster from the original symptom text.\n",
    "\n",
    "This scenario is easier because the labels are now derived from the same features used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f14ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer shape: (25000, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster label distribution:\n",
      "Cluster_Label\n",
      "1    0.32952\n",
      "3    0.21652\n",
      "0    0.18084\n",
      "4    0.16996\n",
      "2    0.10316\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "Scenario C ‚Äì Symptom-Based Clusters: TF‚ÄëIDF + Logistic Regression\n",
      "================================================================================\n",
      "TF‚ÄëIDF shapes: (20000, 649) (5000, 649)\n",
      "\n",
      "Accuracy: 0.9976\n",
      "Most-frequent-class baseline: 0.3295\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.999     1.000     0.999       904\n",
      "           1      1.000     1.000     1.000      1648\n",
      "           2      1.000     0.981     0.990       516\n",
      "           3      0.999     0.999     0.999      1082\n",
      "           4      0.988     0.999     0.994       850\n",
      "\n",
      "    accuracy                          0.998      5000\n",
      "   macro avg      0.997     0.996     0.996      5000\n",
      "weighted avg      0.998     0.998     0.998      5000\n",
      "\n",
      "\n",
      "Scenario C final accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Vectorise all symptom strings with CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "X_symptoms_cv = cv.fit_transform(df[\"Symptoms\"])\n",
    "\n",
    "print(\"CountVectorizer shape:\", X_symptoms_cv.shape)\n",
    "\n",
    "# 5.2 Run K‚ÄëMeans to create k clusters\n",
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_symptoms_cv)\n",
    "\n",
    "# Attach cluster labels to dataframe\n",
    "df_cluster = df.copy()\n",
    "df_cluster[\"Cluster_Label\"] = cluster_labels\n",
    "\n",
    "print(\"\\nCluster label distribution:\")\n",
    "print(df_cluster[\"Cluster_Label\"].value_counts(normalize=True))\n",
    "\n",
    "# 5.3 Train classifier to predict Cluster_Label from Symptoms\n",
    "acc_cluster, clf_cluster, tfidf_cluster, X_train_cluster, X_test_cluster, y_train_cluster, y_test_cluster = train_logreg_tfidf(\n",
    "    texts=df_cluster[\"Symptoms\"],\n",
    "    labels=df_cluster[\"Cluster_Label\"],\n",
    "    description=\"Scenario C ‚Äì Symptom-Based Clusters\",\n",
    ")\n",
    "\n",
    "print(f\"\\nScenario C final accuracy: {acc_cluster:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0cb761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_Label\n",
      "1    8238\n",
      "3    5413\n",
      "0    4521\n",
      "4    4249\n",
      "2    2579\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cluster[\"Cluster_Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684f3fb",
   "metadata": {},
   "source": [
    "## 6. Scenario-Level Summary\n",
    "\n",
    "Here we compare the three scenarios using the same classic ML baseline (TF‚ÄëIDF + Logistic Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca3d358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ FINAL SCENARIO COMPARISON (Classic ML) üèÜ\n",
      "            Scenario  Accuracy\n",
      "    A ‚Äì Raw Diseases  0.033600\n",
      "B ‚Äì Cleaned Diseases  0.033809\n",
      "C ‚Äì Symptom Clusters  0.997600\n"
     ]
    }
   ],
   "source": [
    "results_scenarios = pd.DataFrame(\n",
    "    {\n",
    "        \"Scenario\": [\n",
    "            \"A ‚Äì Raw Diseases\",\n",
    "            \"B ‚Äì Cleaned Diseases\",\n",
    "            \"C ‚Äì Symptom Clusters\",\n",
    "        ],\n",
    "        \"Accuracy\": [acc_raw, acc_clean, acc_cluster],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nüèÜ FINAL SCENARIO COMPARISON (Classic ML) üèÜ\")\n",
    "print(results_scenarios.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683cac0f",
   "metadata": {},
   "source": [
    "## 7. Final Modelling\n",
    "\n",
    "Following the project specification, we now compare **four models** on a single, clearly defined task.\n",
    "\n",
    "We choose **Scenario B ‚Äì Cleaned Diseases** as the main task, because:\n",
    "\n",
    "- It still predicts **real diseases**, not artificial clusters.\n",
    "- Contradictory labels are removed, so the mapping *Symptoms ‚Üí Disease* is at least self‚Äëconsistent.\n",
    "\n",
    "The four models are:\n",
    "\n",
    "1. TF‚ÄëIDF + Logistic Regression (classic model)\n",
    "2. Simple feed‚Äëforward neural network on token embeddings (SimpleNN)\n",
    "3. RNN\n",
    "4. LSTM\n",
    "\n",
    "All models use the **same train/test split** and are evaluated using **accuracy** and a **classification report**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf4495",
   "metadata": {},
   "source": [
    "### 7.1 Build Vocabulary & Sequence Data (Scenario B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a75b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (Scenario B, train only): 60\n",
      "Train seq shape: (19044, 20)\n",
      "Test seq shape: (4762, 20)\n",
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "# We reuse X_train_clean / X_test_clean / y_train_clean / y_test_clean\n",
    "\n",
    "MAX_LEN = 20\n",
    "\n",
    "# Build vocabulary from training text only\n",
    "all_train_words = \" \".join(X_train_clean.values).split()\n",
    "word_counts = Counter(all_train_words)\n",
    "\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for word, _ in word_counts.most_common():\n",
    "    vocab[word] = len(vocab)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size (Scenario B, train only): {vocab_size}\")\n",
    "\n",
    "\n",
    "def encode_text(text_list, vocab, max_len=20):\n",
    "    \"\"\"Convert list/Series of text strings into padded sequences of word IDs.\"\"\"\n",
    "    encoded = []\n",
    "    for text in text_list:\n",
    "        words = text.split()\n",
    "        ids = [vocab.get(w, vocab[\"<UNK>\"]) for w in words]\n",
    "        if len(ids) < max_len:\n",
    "            ids = ids + [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:max_len]\n",
    "        encoded.append(ids)\n",
    "    return np.array(encoded)\n",
    "\n",
    "X_train_seq = encode_text(X_train_clean, vocab, max_len=MAX_LEN)\n",
    "X_test_seq = encode_text(X_test_clean, vocab, max_len=MAX_LEN)\n",
    "\n",
    "print(\"Train seq shape:\", X_train_seq.shape)\n",
    "print(\"Test seq shape:\", X_test_seq.shape)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train_seq).long()\n",
    "y_train_tensor = torch.from_numpy(y_train_clean.values).long()\n",
    "X_test_tensor = torch.from_numpy(X_test_seq).long()\n",
    "y_test_tensor = torch.from_numpy(y_test_clean.values).long()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"DataLoaders ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252683c",
   "metadata": {},
   "source": [
    "### 7.2 Define Neural Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b802c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural architectures defined.\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Feed-forward network on flattened embeddings.\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, max_len):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc1 = nn.Linear(max_len * embed_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)                     # [batch, max_len, embed_dim]\n",
    "        flat = emb.view(emb.size(0), -1)           # [batch, max_len * embed_dim]\n",
    "        h = self.relu(self.fc1(flat))              # [batch, hidden_dim]\n",
    "        logits = self.fc2(h)                       # [batch, output_dim]\n",
    "        return logits\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Vanilla RNN based classifier.\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.rnn(emb)\n",
    "        hidden = hidden.squeeze(0)                # [batch, hidden_dim]\n",
    "        logits = self.fc(hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM based classifier.\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm(emb)\n",
    "        hidden = hidden.squeeze(0)                # [batch, hidden_dim]\n",
    "        logits = self.fc(hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "print(\"Neural architectures defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40aca1c",
   "metadata": {},
   "source": [
    "### 7.3 Training & Evaluation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a550d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, name, train_loader, test_loader, epochs=5, lr=1e-3):\n",
    "    \"\"\"Train a PyTorch model and report test accuracy + classification report.\"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"Training {name}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            total += y_batch.size(0)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"\\n{name} Test Accuracy: {acc:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff352ca",
   "metadata": {},
   "source": [
    "### 7.4 Run the Four-Model Comparison (Scenario B)\n",
    "\n",
    "We now run:\n",
    "\n",
    "1. **Classic ML** ‚Äì the Logistic Regression model already trained as part of Scenario B.  \n",
    "2. **SimpleNN**  \n",
    "3. **RNN**  \n",
    "4. **LSTM**  \n",
    "\n",
    "All on the cleaned-disease task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff5ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Training SimpleNN\n",
      "------------------------------------------------------------\n",
      "Epoch 1/5 - Loss: 3.4065\n",
      "Epoch 2/5 - Loss: 3.4022\n",
      "Epoch 3/5 - Loss: 3.4007\n",
      "Epoch 4/5 - Loss: 3.3959\n",
      "Epoch 5/5 - Loss: 3.3831\n",
      "\n",
      "SimpleNN Test Accuracy: 0.0323\n",
      "\n",
      "Classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.077     0.006     0.011       161\n",
      "           1      0.100     0.006     0.012       156\n",
      "           2      0.031     0.051     0.039       175\n",
      "           3      0.063     0.036     0.045       169\n",
      "           4      0.018     0.007     0.010       150\n",
      "           5      0.500     0.006     0.012       164\n",
      "           6      0.100     0.006     0.012       160\n",
      "           7      0.025     0.026     0.025       154\n",
      "           8      0.074     0.013     0.022       154\n",
      "           9      1.000     0.006     0.013       155\n",
      "          10      0.032     0.600     0.060       165\n",
      "          11      0.000     0.000     0.000       161\n",
      "          12      0.041     0.031     0.035       162\n",
      "          13      0.000     0.000     0.000       158\n",
      "          14      0.050     0.060     0.055       167\n",
      "          15      0.000     0.000     0.000       155\n",
      "          16      0.000     0.000     0.000       152\n",
      "          17      0.000     0.000     0.000       157\n",
      "          18      0.000     0.000     0.000       157\n",
      "          19      0.000     0.000     0.000       159\n",
      "          20      0.000     0.000     0.000       156\n",
      "          21      0.030     0.061     0.040       163\n",
      "          22      0.000     0.000     0.000       155\n",
      "          23      0.000     0.000     0.000       159\n",
      "          24      0.000     0.000     0.000       159\n",
      "          25      0.031     0.007     0.011       151\n",
      "          26      0.000     0.000     0.000       152\n",
      "          27      0.013     0.012     0.013       164\n",
      "          28      0.000     0.000     0.000       155\n",
      "          29      0.000     0.000     0.000       157\n",
      "\n",
      "    accuracy                          0.032      4762\n",
      "   macro avg      0.073     0.031     0.014      4762\n",
      "weighted avg      0.073     0.032     0.014      4762\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training RNN\n",
      "------------------------------------------------------------\n",
      "Epoch 1/5 - Loss: 3.4160\n",
      "Epoch 2/5 - Loss: 3.4099\n",
      "Epoch 3/5 - Loss: 3.4066\n",
      "Epoch 4/5 - Loss: 3.4074\n",
      "Epoch 5/5 - Loss: 3.4067\n",
      "\n",
      "RNN Test Accuracy: 0.0370\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       161\n",
      "           1      0.000     0.000     0.000       156\n",
      "           2      0.039     0.703     0.073       175\n",
      "           3      0.000     0.000     0.000       169\n",
      "           4      0.000     0.000     0.000       150\n",
      "           5      0.042     0.287     0.073       164\n",
      "           6      0.000     0.000     0.000       160\n",
      "           7      0.000     0.000     0.000       154\n",
      "           8      0.000     0.000     0.000       154\n",
      "           9      0.000     0.000     0.000       155\n",
      "          10      0.000     0.000     0.000       165\n",
      "          11      0.000     0.000     0.000       161\n",
      "          12      0.000     0.000     0.000       162\n",
      "          13      0.000     0.000     0.000       158\n",
      "          14      0.000     0.000     0.000       167\n",
      "          15      0.000     0.000     0.000       155\n",
      "          16      0.000     0.000     0.000       152\n",
      "          17      0.000     0.000     0.000       157\n",
      "          18      0.000     0.000     0.000       157\n",
      "          19      0.000     0.000     0.000       159\n",
      "          20      0.000     0.000     0.000       156\n",
      "          21      0.000     0.000     0.000       163\n",
      "          22      0.000     0.000     0.000       155\n",
      "          23      0.000     0.000     0.000       159\n",
      "          24      0.000     0.000     0.000       159\n",
      "          25      0.000     0.000     0.000       151\n",
      "          26      0.000     0.000     0.000       152\n",
      "          27      0.014     0.037     0.020       164\n",
      "          28      0.000     0.000     0.000       155\n",
      "          29      0.000     0.000     0.000       157\n",
      "\n",
      "    accuracy                          0.037      4762\n",
      "   macro avg      0.003     0.034     0.006      4762\n",
      "weighted avg      0.003     0.037     0.006      4762\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 3.4042\n",
      "Epoch 2/5 - Loss: 3.4019\n",
      "Epoch 3/5 - Loss: 3.4015\n",
      "Epoch 4/5 - Loss: 3.4013\n",
      "Epoch 5/5 - Loss: 3.4012\n",
      "\n",
      "LSTM Test Accuracy: 0.0367\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       161\n",
      "           1      0.000     0.000     0.000       156\n",
      "           2      0.037     1.000     0.071       175\n",
      "           3      0.000     0.000     0.000       169\n",
      "           4      0.000     0.000     0.000       150\n",
      "           5      0.000     0.000     0.000       164\n",
      "           6      0.000     0.000     0.000       160\n",
      "           7      0.000     0.000     0.000       154\n",
      "           8      0.000     0.000     0.000       154\n",
      "           9      0.000     0.000     0.000       155\n",
      "          10      0.000     0.000     0.000       165\n",
      "          11      0.000     0.000     0.000       161\n",
      "          12      0.000     0.000     0.000       162\n",
      "          13      0.000     0.000     0.000       158\n",
      "          14      0.000     0.000     0.000       167\n",
      "          15      0.000     0.000     0.000       155\n",
      "          16      0.000     0.000     0.000       152\n",
      "          17      0.000     0.000     0.000       157\n",
      "          18      0.000     0.000     0.000       157\n",
      "          19      0.000     0.000     0.000       159\n",
      "          20      0.000     0.000     0.000       156\n",
      "          21      0.000     0.000     0.000       163\n",
      "          22      0.000     0.000     0.000       155\n",
      "          23      0.000     0.000     0.000       159\n",
      "          24      0.000     0.000     0.000       159\n",
      "          25      0.000     0.000     0.000       151\n",
      "          26      0.000     0.000     0.000       152\n",
      "          27      0.000     0.000     0.000       164\n",
      "          28      0.000     0.000     0.000       155\n",
      "          29      0.000     0.000     0.000       157\n",
      "\n",
      "    accuracy                          0.037      4762\n",
      "   macro avg      0.001     0.033     0.002      4762\n",
      "weighted avg      0.001     0.037     0.003      4762\n",
      "\n",
      "\n",
      "üèÜ FINAL MODEL COMPARISON (Scenario B ‚Äì Cleaned Diseases) üèÜ\n",
      "                       Model  Test Accuracy\n",
      "                         RNN       0.036959\n",
      "                        LSTM       0.036749\n",
      "Logistic Regression (TF‚ÄëIDF)       0.033809\n",
      "                    SimpleNN       0.032339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "num_classes_clean = len(le_clean.classes_)\n",
    "\n",
    "results_models = []\n",
    "\n",
    "# 1. Classic ML accuracy from Scenario B baseline\n",
    "results_models.append((\"Logistic Regression (TF‚ÄëIDF)\", acc_clean))\n",
    "\n",
    "# 2. SimpleNN\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model_nn = SimpleNN(vocab_size, EMBED_DIM, HIDDEN_DIM, num_classes_clean, MAX_LEN)\n",
    "acc_nn = train_and_evaluate(model_nn, \"SimpleNN\", train_loader, test_loader, epochs=5)\n",
    "results_models.append((\"SimpleNN\", acc_nn))\n",
    "\n",
    "# 3. RNN\n",
    "model_rnn = RNNModel(vocab_size, EMBED_DIM, HIDDEN_DIM, num_classes_clean)\n",
    "acc_rnn = train_and_evaluate(model_rnn, \"RNN\", train_loader, test_loader, epochs=5)\n",
    "results_models.append((\"RNN\", acc_rnn))\n",
    "\n",
    "# 4. LSTM\n",
    "model_lstm = LSTMModel(vocab_size, EMBED_DIM, HIDDEN_DIM, num_classes_clean)\n",
    "acc_lstm = train_and_evaluate(model_lstm, \"LSTM\", train_loader, test_loader, epochs=5)\n",
    "results_models.append((\"LSTM\", acc_lstm))\n",
    "\n",
    "results_models_df = pd.DataFrame(results_models, columns=[\"Model\", \"Test Accuracy\"]).sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ FINAL MODEL COMPARISON (Scenario B ‚Äì Cleaned Diseases) üèÜ\")\n",
    "print(results_models_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93899bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
